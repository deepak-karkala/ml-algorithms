{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGOciRwGBthN"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper functions"
      ],
      "metadata": {
        "id": "p2dm9NEiHEEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "8lJdRkoBHQue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading Data"
      ],
      "metadata": {
        "id": "xDsoZ8t3HEP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from google.colab import files\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"Uploading_Data_Colab_1.xlsx\" with length 9000 bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\"\"\"\n",
        "\n",
        "!wget -cq https://download.pytorch.org/tutorial/data.zip\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')"
      ],
      "metadata": {
        "id": "VFYIaS17HUeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNVF_RHuBthP"
      },
      "source": [
        "## Loading and pre-processing data files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDGGk20WBthT",
        "outputId": "8a699d0c-498f-44d1-e825-16d2d6e8ec19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n",
            "['on n a plus le temps', 'we re out of time']\n"
          ]
        }
      ],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "\n",
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "\n",
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))\n",
        "\n",
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)\n",
        "\n",
        "def get_dataloader(batch_size):\n",
        "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = indexesFromSentence(input_lang, inp)\n",
        "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8fz9b8VBthX"
      },
      "source": [
        "### Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUsyOwYNBthX"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP6GtSQ2BthX"
      },
      "source": [
        "### Decoder with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4Gq_-E2BthY"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, dim_attention, dim_keys, dim_query):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(dim_attention, dim_query)\n",
        "        self.Ua = nn.Linear(dim_attention, dim_keys)\n",
        "        self.Va = nn.Linear(dim_attention, 1)\n",
        "\n",
        "    def forward(self, query, keys, values):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, values)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "\n",
        "class AttentionDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout=0.1):\n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size, hidden_size, hidden_size)\n",
        "        self.gru = nn.GRU(2*hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        context, attention_weights = self.attention(query=hidden.permute(1, 0, 2), keys=encoder_outputs, values=encoder_outputs)\n",
        "\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attention_weights\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_hidden= encoder_hidden\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        # Run the decoder for MAX_LENGTH number of steps\n",
        "        for i in range(MAX_LENGTH):\n",
        "            # One step of decoder\n",
        "            decoder_output, decoder_hidden, attention_weight = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attention_weight)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                # Teacher forcing: using target as next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                # Using decoder output in this step as input to next step\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GVXFwySkgDvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seq2Seq Model"
      ],
      "metadata": {
        "id": "j4Icll7ALP0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seqAttention(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(seq2seqAttention, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, input_tensor, target_tensor):\n",
        "        # Forward propagation through encoder and decoder (one batch, MAX_LENGTH time steps)\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, attentions = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "        return decoder_outputs, decoder_hidden, attentions"
      ],
      "metadata": {
        "id": "4JZpseQbLOtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgEdbX7kBthY"
      },
      "source": [
        "### Training script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lf71nvTZBthZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    # Optimizers and loss function\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # Train network for on epoch\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        # Reset optimizers\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        # Forward propagation through encoder and decoder (one batch, MAX_LENGTH time steps)\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        # Compute loss: NLL\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        # Back propagate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update network parameters\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\"\"\"\n",
        "\n",
        "def train(train_dataloader, model, n_epochs, learning_rate=0.001, print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    # Optimizers and loss function\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # Train network for on epoch\n",
        "        loss = train_epoch(train_dataloader, model, optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)\n",
        "\n",
        "def train_epoch(dataloader, model, optimizer, criterion):\n",
        "    total_loss = 0\n",
        "\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        # Reset optimizers\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward propagation through encoder and decoder (one batch, MAX_LENGTH time steps)\n",
        "        decoder_outputs, _, _ = model(input_tensor, target_tensor)\n",
        "\n",
        "        # Compute loss: NLL\n",
        "        y = target_tensor.view(-1)\n",
        "        y_pred = decoder_outputs.view(-1, decoder_outputs.size(-1))\n",
        "        loss = criterion(y_pred, y)\n",
        "        # Back propagate gradients\n",
        "        loss.backward()\n",
        "\n",
        "        # Update network parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the network"
      ],
      "metadata": {
        "id": "wlzS7R8bKaPO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttentionDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "model = seq2seqAttention(encoder, decoder).to(device)"
      ],
      "metadata": {
        "id": "u0ORy0kAORIL",
        "outputId": "3f6e9dac-7513-454c-e1c1-482a5608fa58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 11445 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4601\n",
            "eng 2991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b07WfNOYBthZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train(train_dataloader, encoder, decoder, 80, print_every=5, plot_every=5)\n",
        "train(train_dataloader, model, 1, print_every=5, plot_every=5)"
      ],
      "metadata": {
        "id": "lEIocPUyKqjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')\n",
        "\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "id": "Ce9qgkkwK1xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With Keras model.fit()\n"
      ],
      "metadata": {
        "id": "7jhFO_WIO82Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# This guide can only be run with the torch backend.\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import keras\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "mfL_VbHJSWx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seqAttentionKeras(keras.Model):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(seq2seqAttentionKeras, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, input_tensor, training=True):\n",
        "        # Forward propagation through encoder and decoder (one batch, MAX_LENGTH time steps)\n",
        "        print(input_tensor.type)\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, attentions = decoder(encoder_outputs, encoder_hidden)\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "    def train_step(self, data):\n",
        "        for step, (inputs, targets) in enumerate(data):\n",
        "            # Forward pass\n",
        "            #decoder_outputs, _, _ = self(inputs)\n",
        "            encoder_outputs, encoder_hidden = encoder(inputs)\n",
        "            decoder_outputs, decoder_hidden, attentions = decoder(encoder_outputs, encoder_hidden)\n",
        "            logits = decoder_outputs.view(-1, decoder_outputs.size(-1))\n",
        "            loss = loss_fn(logits, targets.view(-1))\n",
        "\n",
        "            # Backward pass\n",
        "            modelKeras.zero_grad()\n",
        "            trainable_weights = [v for v in modelKeras.trainable_weights]\n",
        "\n",
        "            # Backpropagate loss to compute gradients for the weights.\n",
        "            loss.backward()\n",
        "            gradients = [v.value.grad for v in trainable_weights]\n",
        "\n",
        "            # Update weights\n",
        "            with torch.no_grad():\n",
        "                optimizer.apply(gradients, trainable_weights)\n",
        "\n",
        "            \"\"\"\n",
        "            # Log every 100 batches.\n",
        "            if step % 100 == 0:\n",
        "                print(\n",
        "                    f\"Training loss (for 1 batch) at step {step}: {loss.detach().cpu().numpy():.4f}\"\n",
        "                )\n",
        "                print(f\"Seen so far: {(step + 1) * batch_size} samples\")\n",
        "            \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        x, y = data\n",
        "\n",
        "        # Call torch.nn.Module.zero_grad() to clear the leftover gradients\n",
        "        # for the weights from the previous train step.\n",
        "        self.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        # encoder_outputs, encoder_hidden = self.encoder(x)\n",
        "        # decoder_outputs, decoder_hidden, attentions = self.decoder(encoder_outputs, encoder_hidden, y)\n",
        "        decoder_outputs, decoder_hidden, attentions = self(x.to(torch.int64), training=True)\n",
        "        y_pred = decoder_outputs.view(-1, decoder_outputs.size(-1))\n",
        "\n",
        "        # Compute loss\n",
        "        loss = self.compute_loss(y=y, y_pred=y_pred)\n",
        "\n",
        "        # Call torch.Tensor.backward() on the loss to compute gradients\n",
        "        # for the weights.\n",
        "        loss.backward()\n",
        "\n",
        "        trainable_weights = [v for v in self.trainable_weights]\n",
        "        gradients = [v.value.grad for v in trainable_weights]\n",
        "\n",
        "        # Update weights\n",
        "        with torch.no_grad():\n",
        "            self.optimizer.apply(gradients, trainable_weights)\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        for metric in self.metrics:\n",
        "            if metric.name == \"loss\":\n",
        "                metric.update_state(loss)\n",
        "            else:\n",
        "                metric.update_state(y, y_pred)\n",
        "\n",
        "        # Return a dict mapping metric names to current value\n",
        "        # Note that it will include the loss (tracked in self.metrics).\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        return loss\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "2y1bjK5fO4LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttentionDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "modelKeras = seq2seqAttentionKeras(encoder, decoder).to(device)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for step, (inputs, targets) in enumerate(train_dataloader):\n",
        "        # Forward pass\n",
        "        decoder_outputs, _, _ = modelKeras(inputs)\n",
        "        logits = decoder_outputs.view(-1, decoder_outputs.size(-1))\n",
        "        loss = loss_fn(logits, targets.view(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Optimizer variable updates\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "KPGEyWWwdlgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttentionDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "modelKeras = seq2seqAttentionKeras(encoder, decoder).to(device)\n",
        "\n",
        "loss_fn = nn.NLLLoss() #keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "for epoch in range(10):\n",
        "    print(f\"\\nStart of epoch {epoch}\")\n",
        "    for step, (inputs, targets) in enumerate(train_dataloader):\n",
        "        # Forward pass\n",
        "        decoder_outputs, _, _ = modelKeras(inputs)\n",
        "        logits = decoder_outputs.view(-1, decoder_outputs.size(-1))\n",
        "        loss = loss_fn(logits, targets.view(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        modelKeras.zero_grad()\n",
        "        trainable_weights = [v for v in modelKeras.trainable_weights]\n",
        "\n",
        "        # Call torch.Tensor.backward() on the loss to compute gradients\n",
        "        # for the weights.\n",
        "        loss.backward()\n",
        "        gradients = [v.value.grad for v in trainable_weights]\n",
        "\n",
        "        # Update weights\n",
        "        with torch.no_grad():\n",
        "            optimizer.apply(gradients, trainable_weights)\n",
        "\n",
        "        # Log every 100 batches.\n",
        "        if step % 100 == 0:\n",
        "            print(\n",
        "                f\"Training loss (for 1 batch) at step {step}: {loss.detach().cpu().numpy():.4f}\"\n",
        "            )\n",
        "            print(f\"Seen so far: {(step + 1) * batch_size} samples\")"
      ],
      "metadata": {
        "id": "Abw-14qfi6fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelKeras = seq2seqAttentionKeras(encoder, decoder).to(device)\n",
        "input, target = next(iter(train_dataloader))\n",
        "modelKeras(input)\n",
        "\n",
        "modelKeras.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss=nn.NLLLoss(),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy()])"
      ],
      "metadata": {
        "id": "NCIhpa5jRkl3",
        "outputId": "99571479-506a-4a94-b9e2-065a04e743b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method type of Tensor object at 0x7ff16bd29670>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelKeras.fit(\n",
        "    train_dataloader,\n",
        "    epochs=1,\n",
        "    steps_per_epoch = 1,\n",
        "    validation_data=train_dataloader,\n",
        "    validation_steps = 1,\n",
        ") #callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])"
      ],
      "metadata": {
        "id": "YjgZ89toW5u-",
        "outputId": "b7e78049-9ce8-409a-adf3-b28286ffcbd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method type of Tensor object at 0x7ff16bd0e9d0>\n",
            "<built-in method type of Tensor object at 0x7ff16bd510d0>\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Exception encountered when calling seq2seqAttentionKeras.call().\n\n\u001b[1mExpected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)\u001b[0m\n\nArguments received by seq2seqAttentionKeras.call():\n  • input_tensor=torch.Tensor(shape=torch.Size([32, 10]), dtype=float32)\n  • training=True'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-f51219118fd5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = modelKeras.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/torch/trainer.py\u001b[0m in \u001b[0;36m_symbolic_build\u001b[0;34m(self, data_batch)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    191\u001b[0m                     \u001b[0;34m\"Unable to automatically build the model. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0;34m\"Please build it yourself before calling \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unable to automatically build the model. Please build it yourself before calling fit/evaluate/predict. A model is 'built' when its variables have been created and its `self.built` attribute is True. Usually, calling the model on a batch of data is the right way to build it.\nException encountered:\n'Exception encountered when calling seq2seqAttentionKeras.call().\n\n\u001b[1mExpected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)\u001b[0m\n\nArguments received by seq2seqAttentionKeras.call():\n  • input_tensor=torch.Tensor(shape=torch.Size([32, 10]), dtype=float32)\n  • training=True'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow + Keras"
      ],
      "metadata": {
        "id": "WWF5LZtXcUst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "JSTDTDMFUnbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "\n",
        "        # Embedding layer converts tokens to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(input_size, hidden_size, mask_zero=True)\n",
        "        # RNN layer to process sentence sequentially\n",
        "        self.gru = tf.keras.layers.Bidirectional(\n",
        "            merge_mode='sum',\n",
        "            layer = tf.keras.layers.GRU(hidden_size, return_sequences=True,\n",
        "                                        recurrent_initializer='glorot_uniform'))\n",
        "    def call(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.rnn(x)\n",
        "        return x\n",
        "\n",
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, hidden_size, **kwargs):\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=hidden_size, num_heads=1, **kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, input, context):\n",
        "        attn_output, attn_scores = self.mha(query=input, value=context, return_attention_scores=True)\n",
        "        x = self.add([input, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class AttentionDecoderRNN(tf.keras.layers.Layer):\n",
        "    def __init__(self, output_size, hidden_size):\n",
        "        super(AttentionDecoderRNN, self).__init__()\n",
        "        # Embedding layer converts tokens to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(output_size, hidden_size, mask_zero=True)\n",
        "        # RNN layer to process sentence sequentially\n",
        "        self.rnn = tf.keras.layers.GRU(hidden_size, return_sequences=True, return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "        # Decoder RNN output will be the query for the attention layer.\n",
        "        self.attention = CrossAttention(hidden_size)\n",
        "        # Output layer to produce logits\n",
        "        self.output_layer = tf.keras.layers.Dense(output_size)\n",
        "\n",
        "    def call(self, input, context, state=None, return_state=False):\n",
        "        # Lookup the embeddings\n",
        "        x = self.embedding(input)\n",
        "        # Process the target sequence.\n",
        "        x, state = self.rnn(x, initial_state=state)\n",
        "        # Use the RNN output as the query for the attention over the context.\n",
        "        x = self.attention(x, context)\n",
        "        # Generate logit predictions for the next token.\n",
        "        logits = self.output_layer(x)\n",
        "\n",
        "        if return_state:\n",
        "          return logits, state\n",
        "        else:\n",
        "          return logits\n",
        "\n",
        "class Translator(tf.keras.Model):\n",
        "      def __init__(self, input_size, hidden_size, output_size):\n",
        "          super().__init__()\n",
        "          # Build the encoder and decoder\n",
        "          encoder = Encoder(input_size, hidden_size)\n",
        "          decoder = Decoder(output_size, hidden_size)\n",
        "\n",
        "          self.encoder = encoder\n",
        "          self.decoder = decoder\n",
        "\n",
        "      def call(self, inputs):\n",
        "          def call(self, inputs):\n",
        "          context, x = inputs\n",
        "          context = self.encoder(context)\n",
        "          logits = self.decoder(x, context)\n",
        "          return logits\n",
        "\n",
        "      @tf.function\n",
        "      # Compile into a static graph for faster training\n",
        "      def train_step(self, data):\n",
        "          x, y = data\n",
        "\n",
        "          # Forward pass and compute loss\n",
        "          with tf.GradientTape() as tape:\n",
        "              logits = self(x, training=True)\n",
        "              loss_value = self.loss(y, logits)\n",
        "\n",
        "          # Backprop and compute gradients\n",
        "          grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "          # Update weights\n",
        "          self.optimizer.apply(grads, model.trainable_weights)\n",
        "\n",
        "          return loss_value\n",
        "\n",
        "model = Translator(input_size, hidden_size, output_size);\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_fn)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds.repeat(),\n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 20,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=3)])"
      ],
      "metadata": {
        "id": "h-hQ-UIyqKve"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}