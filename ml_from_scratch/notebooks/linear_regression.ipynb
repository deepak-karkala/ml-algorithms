{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "# from sklearn.preprocessing import normalize\n",
    "#from ml_from_scratch.utils import normalize, standardize, polynomial_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X, degree):\n",
    "    n_samples, n_features = np.shape(X)\n",
    "\n",
    "    def index_combinations():\n",
    "        combs = [combinations_with_replacement(range(n_features), i) for i in range(0, degree + 1)]\n",
    "        flat_combs = [item for sublist in combs for item in sublist]\n",
    "        return flat_combs\n",
    "    \n",
    "    combinations = index_combinations()\n",
    "    n_output_features = len(combinations)\n",
    "    X_new = np.empty((n_samples, n_output_features))\n",
    "    \n",
    "    for i, index_combs in enumerate(combinations):  \n",
    "        X_new[:, i] = np.prod(X[:, index_combs], axis=1)\n",
    "\n",
    "    return X_new\n",
    "\n",
    "\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    \"\"\"Normalise the dataset (unit norm)\n",
    "        Axis:0 => Each feature(column) is normalised to unit norm\n",
    "        Axis:1 => Each sample(row) is normalised to unit norm\n",
    "        X = X / sqrt(|X|^2)\n",
    "    \"\"\"\n",
    "    norm = np.atleast_1d(np.linalg.norm(X, ord=order, axis=axis))\n",
    "    norm[norm == 0] = 1\n",
    "    return X / np.expand_dims(norm, axis=axis)\n",
    "\n",
    "\n",
    "def standardize(X):\n",
    "    \"\"\"Standardize the dataset to make features\n",
    "    zero mean and unit variance\n",
    "    \"\"\"\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\" Returns the mean squared error between y_true and y_pred \"\"\"\n",
    "    #mse = np.mean(np.power(y_true - y_pred, 2))\n",
    "    mse = np.mean((y_true - y_pred)**2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class l1_regularization():\n",
    "    \"\"\"Lasso regularization\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        return self.alpha * np.linalg.norm(w, ord=1)\n",
    "    \n",
    "    def grad(self, w):\n",
    "        return self.alpha * np.sign(w)\n",
    "\n",
    "class l2_regularization():\n",
    "    \"\"\" L2 regularization \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        return self.alpha * 0.5 * ((w.T @ w).item())\n",
    "        # return self.alpha * 0.5 * ((w.T).dot(w).item())\n",
    "        # return self.alpha * 0.5 * np.linalg.norm(w, ord=2)**2\n",
    "    \n",
    "    def grad(self, w):\n",
    "        return self.alpha * w\n",
    "\n",
    "\n",
    "class l1_l2_regularization():\n",
    "    \"\"\"Elastic net regularization\"\"\"\n",
    "    def __init__(self, alpha, l1_ratio):\n",
    "        self.alpha = alpha\n",
    "        self.l1_ratio = l1_ratio\n",
    "    \n",
    "    def __call__(self, w):\n",
    "        l1_reg = self.l1_ratio * np.linalg.norm(w, ord=1)\n",
    "        l2_reg = (1 - self.l1_ratio) * 0.5 * (w.T @ w).item()\n",
    "        return self.alpha * (l1_reg + l2_reg)\n",
    "    \n",
    "    def grad(self, w):\n",
    "        return self.alpha * (self.l1_ratio * np.sign(w) + (1-self.l1_ratio)*w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(object):\n",
    "    \"\"\"\n",
    "    Models relationship b/w  independent variables X and dependent variable y\n",
    "    Base class for linear regression models\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_iterations: float\n",
    "        Number of training iterations\n",
    "    learning_rate: float\n",
    "        Step size of optimisation algorithm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_iterations, learning_rate):\n",
    "        self.n_iterations = n_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def initialize_weights(self, n_features):\n",
    "        \"\"\"Initialise weights randomly b/w [-1/sqrt(N) 1/sqrt(N)]\"\"\"\n",
    "        limit = 1 / math.sqrt(n_features)\n",
    "        self.w = np.random.uniform(-limit, limit, (n_features, 1))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Learn parameters using supervised data\"\"\"\n",
    "        # Insert column of 1s for bias term\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        # Initialise weights\n",
    "        self.initialize_weights(n_features=X.shape[1])\n",
    "        self.training_errors = []\n",
    "\n",
    "        # Gradient descent for n_iterations\n",
    "        for i in range(self.n_iterations):\n",
    "            # Predicted output\n",
    "            # y_pred = X.dot(self.w)\n",
    "            y_pred = X @ self.w\n",
    "            # Error (target - predicted)\n",
    "            # L2 Loss\n",
    "            mse = np.mean(0.5*(y - y_pred)**2) + self.regularization(self.w)\n",
    "            self.training_errors.append(mse)\n",
    "            # Gradient of error\n",
    "            #grad_w = -(y - y_pred).dot(X) + self.regularization.grad(self.w) #will work only if y has dimensions (n,)\n",
    "            grad_w = -(X.T) @ (y - y_pred) + self.regularization.grad(self.w)\n",
    "            #print(grad_w.shape)\n",
    "            #print(self.w.shape)\n",
    "            # Gradient descent step\n",
    "            self.w -= self.learning_rate * grad_w\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predictions for new data\"\"\"\n",
    "        X = np.insert(X, 0, 1, axis=1)\n",
    "        y_pred = X.dot(self.w)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(Regression):\n",
    "    \"\"\"Linear Regression Model\n",
    "    \"\"\"\n",
    "    def __init__(self, n_iterations=100, learning_rate=0.0001, gradient_descent=True):\n",
    "        self.gradient_descent = gradient_descent\n",
    "        # No regularisation\n",
    "        self.regularization = lambda x: 0\n",
    "        self.regularization.grad = lambda x: 0\n",
    "        super(LinearRegression, self).__init__(n_iterations=n_iterations, learning_rate=learning_rate)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        If gradient descent use base class's fit\n",
    "        If not gradient descent use normal equations (inverse using SVD)\n",
    "        \"\"\"\n",
    "        if self.gradient_descent:\n",
    "            super(LinearRegression, self).fit(X, y)\n",
    "        else:\n",
    "            X = np.insert(X, 0, 1, axis=1)\n",
    "            \"\"\"\n",
    "            # Moore-Penrose pseudo inverse using SVD (TODO: incorrect estimates)\n",
    "            U, S, V = np.linalg.svd(X.T.dot(X))\n",
    "            S = np.diag(S)\n",
    "            Xtx_inv = V.dot(np.linalg.pinv(S)).dot(U.T)\n",
    "            self.w = Xtx_inv.dot(X.T).dot(y)\n",
    "            \"\"\"\n",
    "            self.w = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y) # Normal equation, psuedo inverse\n",
    "            self.training_errors = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression(Regression):\n",
    "    \"\"\"Performs a non-linear transformation of the data before fitting the model\n",
    "    and doing predictions which allows for doing non-linear regression.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    degree: float\n",
    "        Polynomial degree\n",
    "    \"\"\"\n",
    "    def __init__(self, degree, n_iterations=1000, learning_rate=0.001):\n",
    "        self.degree = degree\n",
    "        self.regularization = lambda x: 0\n",
    "        self.regularization.grad = lambda x: 0\n",
    "        super(PolynomialRegression, self).__init__(n_iterations=n_iterations, learning_rate=learning_rate)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = polynomial_features(X, degree=self.degree)\n",
    "        super(PolynomialRegression, self).fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = polynomial_features(X, degree=self.degree)\n",
    "        return super(PolynomialRegression, self).predict(X)\n",
    "\n",
    "\n",
    "\n",
    "class LassoRegression(Regression):\n",
    "    \"\"\"Lasso Regression (with polynomial features) - l1 regularisation\n",
    "    Paramaters:\n",
    "    ----------\n",
    "    degree: int\n",
    "        Degree of polynomial features\n",
    "    reg_factor: float\n",
    "        Regularisation parameter (Feature shrinkage)\n",
    "    \"\"\"\n",
    "    def __init__(self, degree, reg_factor, n_iterations=100, learning_rate=0.0001):\n",
    "        self.degree = degree\n",
    "        self.regularization = l1_regularization(alpha = reg_factor)\n",
    "        super(LassoRegression, self).__init__(n_iterations=n_iterations, learning_rate=learning_rate)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # [TODO - High error with polynomial features]\n",
    "        #X = normalize(polynomial_features(X, degree=self.degree))\n",
    "        super(LassoRegression, self).fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #X = normalize(polynomial_features(X, degree=self.degree))\n",
    "        return super(LassoRegression, self).predict(X)\n",
    "\n",
    "\n",
    "class RidgeRegression(Regression):\n",
    "    \"\"\"Ridge Regression (with polynomial features) - l2 regularisation\n",
    "    Paramaters:\n",
    "    ----------\n",
    "    degree: int\n",
    "        Degree of polynomial features\n",
    "    reg_factor: float\n",
    "        Regularisation parameter (Feature shrinkage)\n",
    "    \"\"\"\n",
    "    def __init__(self, degree, reg_factor, n_iterations=100, learning_rate=0.0001):\n",
    "        self.degree = degree\n",
    "        self.regularization = l2_regularization(alpha = reg_factor)\n",
    "        super(RidgeRegression, self).__init__(n_iterations=n_iterations, learning_rate=learning_rate)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #X = normalize(polynomial_features(X, degree=self.degree))\n",
    "        super(RidgeRegression, self).fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #X = normalize(polynomial_features(X, degree=self.degree))\n",
    "        return super(RidgeRegression, self).predict(X)\n",
    "\n",
    "\n",
    "class ElasticNet(Regression):\n",
    "    \"\"\"Regression (with polynomial features) - with l1 and l2 regularisation\n",
    "    Paramaters:\n",
    "    ----------\n",
    "    degree: int\n",
    "        Degree of polynomial features\n",
    "    reg_factor: float\n",
    "        Regularisation parameter (Feature shrinkage)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, degree, reg_factor, l1_ratio, n_iterations=100, learning_rate=0.0001):\n",
    "        self.degree = degree\n",
    "        self.regularization = l1_l2_regularization(alpha = reg_factor, l1_ratio=l1_ratio)\n",
    "        super(ElasticNet, self).__init__(n_iterations=n_iterations, learning_rate=learning_rate)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #X = normalize(polynomial_features(X, degree=self.degree))\n",
    "        super(ElasticNet, self).fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        #X = normalize(polynomial_features(X, degree=self.degree))\n",
    "        return super(ElasticNet, self).predict(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "n_features = 1\n",
    "test_size = 0.25\n",
    "n_iterations = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_regression(n_samples=n_samples, n_features=n_features, noise=0)\n",
    "\n",
    "# Create train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "#print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape\n",
    "y = y.reshape(y.shape[0], 1)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "#model = LinearRegression(n_iterations=100, learning_rate=learning_rate, gradient_descent=True)\n",
    "model = LassoRegression(degree=1, reg_factor=0.1, n_iterations=100, learning_rate=learning_rate)\n",
    "#model = RidgeRegression(degree=1, reg_factor=0.1, n_iterations=100, learning_rate=learning_rate)\n",
    "#model = ElasticNet(degree=1, reg_factor=0.1, l1_ratio=0.25, n_iterations=100, learning_rate=learning_rate)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "#print(mean_squared_error(y_pred, y_test))\n",
    "\n",
    "# Training error plot\n",
    "n = len(model.training_errors)\n",
    "training, = plt.plot(range(n), model.training_errors, label=\"Training Error\")\n",
    "plt.legend(handles=[training])\n",
    "plt.title(\"Error Plot\")\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.527709073538586e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d58b18e7b01016a91099f7b9ff9e04a9c7fe388e7a62de199c633b2e4fde8ca4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
