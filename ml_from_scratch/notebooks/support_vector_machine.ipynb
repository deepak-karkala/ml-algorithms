{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define kernels\n",
    "\n",
    "def linear_kernel(**kwargs):\n",
    "    def f(x1, x2):\n",
    "        return np.inner(x1, x2)\n",
    "    return f\n",
    "\n",
    "def polynomial_kernel(power, coef, **kwargs):\n",
    "    def f(x1, x2):\n",
    "        return (np.inner(x1, x2) + coef)**power\n",
    "    return f\n",
    "\n",
    "def rbf_kernel(gamma, **kwargs):\n",
    "    def f(x1, x2):\n",
    "        distance = np.linalg.norm(x1 - x2)**2\n",
    "        return np.exp(-gamma * distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "\n",
    "class SupportVectorMachine(object):\n",
    "    \"\"\"Support vector classifier\n",
    "    Parameters\n",
    "    ----------\n",
    "    C: float\n",
    "        Penalty term\n",
    "    kernel: function\n",
    "        Kernel function (linear, gaussian, polynomial)\n",
    "    gamma: float\n",
    "    power: int\n",
    "    coef: float\n",
    "        Bias term in polynomial function\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1, kernel=rbf_kernel, power=4, gamma=None, coef=4):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.gamma = gamma\n",
    "        self.power = power\n",
    "        self.coef = coef\n",
    "        self.lagr_multipliers = None\n",
    "        self.support_vectors = None\n",
    "        self.support_vectors_labels = None\n",
    "        self.intercept = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \"\"\"Find SVM parameters\n",
    "        (Lagrange multipliers, corresponding support vectors)\n",
    "        \"\"\"\n",
    "        n_samples, n_features = np.shape(x)\n",
    "\n",
    "        if not self.gamma:\n",
    "            self.gamma = 1/n_features\n",
    "        \n",
    "        # Instantiate kernel\n",
    "        self.kernel = self.kernel(\n",
    "            power = self.power,\n",
    "            coef = self.coef,\n",
    "            gamma = self.gamma\n",
    "        )\n",
    "\n",
    "        # Find kernel matrix\n",
    "        kernel_matrix = np.zeros((n_samples, n_samples))\n",
    "        for i in range(n_samples):\n",
    "            for j in range(n_samples):\n",
    "                kernel_matrix[i, j] = self.kernel(x[i], x[j])\n",
    "        \n",
    "        # Solve the quadratic optimization problem using cvxopt package\n",
    "        # [TODO: Understand how to formulate QP optimisation]\n",
    "        P = cvxopt.matrix(np.outer(y, y) * kernel_matrix, tc='d')\n",
    "        q = cvxopt.matrix(np.ones(n_samples) * -1)\n",
    "        A = cvxopt.matrix(y, (1, n_samples), tc='d')\n",
    "        b = cvxopt.matrix(0, tc='d')\n",
    "\n",
    "        if not self.C:\n",
    "            G = cvxopt.matrix(np.identity(n_samples) * -1)\n",
    "            h = cvxopt.matrix(np.zeros(n_samples))\n",
    "        else:\n",
    "            G_max = np.identity(n_samples) * -1\n",
    "            G_min = np.identity(n_samples)\n",
    "            G = cvxopt.matrix(np.vstack((G_max, G_min)))\n",
    "            h_max = cvxopt.matrix(np.zeros(n_samples))\n",
    "            h_min = cvxopt.matrix(np.ones(n_samples) * self.C)\n",
    "            h = cvxopt.matrix(np.vstack((h_max, h_min)))\n",
    "\n",
    "        # Solve the quadratic optimization problem using cvxopt\n",
    "        minimization = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        lagr_multipliers = np.ravel(minimization['x'])\n",
    "\n",
    "        # Select non-zero lagr_multipliers (alpha)\n",
    "        idx = lagr_multipliers > 1e-7\n",
    "        self.lagr_multipliers = lagr_multipliers[idx]\n",
    "        # Select corresponding support vectors and y labels\n",
    "        self.support_vectors = x[idx]\n",
    "        self.support_vectors_labels = y[idx]\n",
    "\n",
    "        # Calculate intercept (TODO: How?)\n",
    "        self.intercept = self.support_vectors_labels[0]\n",
    "        for i in range(len(self.lagr_multipliers)):\n",
    "            self.intercept -= self.lagr_multipliers[i] * self.support_vectors_labels[\n",
    "                i] * self.kernel(self.support_vectors[i], self.support_vectors[0])\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\" Get SVM prediction\n",
    "        (Weighted (lagr_multipliers) sum of kernel outputs with support vectors)\n",
    "        \"\"\"\n",
    "        y_pred = []\n",
    "        for sample in x:\n",
    "            pred = 0\n",
    "            # Iterate over support vectors\n",
    "            for i in range(len(self.lagr_multipliers)):\n",
    "                pred += self.lagr_multipliers[i] * self.support_vectors_labels[\n",
    "                    i] * self.kernel(self.support_vectors[i], sample)\n",
    "            pred += self.intercept\n",
    "            y_pred.append(np.sign(pred))\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.7549e+01 -1.2988e+02  5e+02  2e+00  1e-14\n",
      " 1: -1.2056e+01 -7.4828e+01  6e+01  3e-16  1e-14\n",
      " 2: -1.5831e+01 -2.4167e+01  8e+00  2e-16  1e-14\n",
      " 3: -1.8827e+01 -2.0623e+01  2e+00  2e-16  1e-14\n",
      " 4: -1.9479e+01 -1.9898e+01  4e-01  2e-16  1e-14\n",
      " 5: -1.9650e+01 -1.9723e+01  7e-02  4e-16  1e-14\n",
      " 6: -1.9683e+01 -1.9688e+01  4e-03  4e-16  1e-14\n",
      " 7: -1.9685e+01 -1.9685e+01  1e-04  4e-16  2e-14\n",
      " 8: -1.9685e+01 -1.9685e+01  1e-06  4e-16  1e-14\n",
      "Optimal solution found.\n",
      "Accuracy: 0.9090909090909091\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n",
    "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "def normalize(X, axis=-1, order=2):\n",
    "    \"\"\"Normalise the dataset (unit norm)\n",
    "        Axis:0 => Each feature(column) is normalised to unit norm\n",
    "        Axis:1 => Each sample(row) is normalised to unit norm\n",
    "        X = X / sqrt(sum|X|^2)\n",
    "    \"\"\"\n",
    "    norm = np.atleast_1d(np.linalg.norm(X, ord=order, axis=axis))\n",
    "    norm[norm == 0] = 1\n",
    "    return X / np.expand_dims(norm, axis=axis)\n",
    "\n",
    "data = datasets.load_iris()\n",
    "X = normalize(data.data[data.target != 0])\n",
    "y = data.target[data.target != 0]\n",
    "y[y == 1] = -1\n",
    "y[y == 2] = 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "clf = SupportVectorMachine(kernel=polynomial_kernel, power=4, coef=1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print (\"Accuracy:\", accuracy)\n",
    "\n",
    "# Reduce dimension to two using PCA and plot the results\n",
    "Plot().plot_in_2d(X_test, y_pred, title=\"Support Vector Machine\", accuracy=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "\n",
    "def standardize(X):\n",
    "    \"\"\" Standardize the dataset X \"\"\"\n",
    "    X_std = X\n",
    "    mean = X.mean(axis=0)\n",
    "    std = X.std(axis=0)\n",
    "    for col in range(np.shape(X)[1]):\n",
    "        if std[col]:\n",
    "            X_std[:, col] = (X_std[:, col] - mean[col]) / std[col]\n",
    "    # X_std = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    return X_std\n",
    "\n",
    "def calculate_covariance_matrix(X, Y=None):\n",
    "    \"\"\" Calculate the covariance matrix for the dataset X \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance_matrix = (1 / (n_samples-1)) * (X - X.mean(axis=0)).T.dot(Y - Y.mean(axis=0))\n",
    "\n",
    "    return np.array(covariance_matrix, dtype=float)\n",
    " \n",
    "\n",
    "def calculate_correlation_matrix(X, Y=None):\n",
    "    \"\"\" Calculate the correlation matrix for the dataset X \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance = (1 / n_samples) * (X - X.mean(0)).T.dot(Y - Y.mean(0))\n",
    "    std_dev_X = np.expand_dims(calculate_std_dev(X), 1)\n",
    "    std_dev_y = np.expand_dims(calculate_std_dev(Y), 1)\n",
    "    correlation_matrix = np.divide(covariance, std_dev_X.dot(std_dev_y.T))\n",
    "\n",
    "    return np.array(correlation_matrix, dtype=float)\n",
    "\n",
    "\n",
    "bar_widgets = [\n",
    "    'Training: ', progressbar.Percentage(), ' ', progressbar.Bar(marker=\"-\", left=\"[\", right=\"]\"),\n",
    "    ' ', progressbar.ETA()\n",
    "]\n",
    "\n",
    "class Plot():\n",
    "    def __init__(self): \n",
    "        self.cmap = plt.get_cmap('viridis')\n",
    "\n",
    "    def _transform(self, X, dim):\n",
    "        covariance = calculate_covariance_matrix(X)\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(covariance)\n",
    "        # Sort eigenvalues and eigenvector by largest eigenvalues\n",
    "        idx = eigenvalues.argsort()[::-1]\n",
    "        eigenvalues = eigenvalues[idx][:dim]\n",
    "        eigenvectors = np.atleast_1d(eigenvectors[:, idx])[:, :dim]\n",
    "        # Project the data onto principal components\n",
    "        X_transformed = X.dot(eigenvectors)\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "\n",
    "    def plot_regression(self, lines, title, axis_labels=None, mse=None, scatter=None, legend={\"type\": \"lines\", \"loc\": \"lower right\"}):\n",
    "        \n",
    "        if scatter:\n",
    "            scatter_plots = scatter_labels = []\n",
    "            for s in scatter:\n",
    "                scatter_plots += [plt.scatter(s[\"x\"], s[\"y\"], color=s[\"color\"], s=s[\"size\"])]\n",
    "                scatter_labels += [s[\"label\"]]\n",
    "            scatter_plots = tuple(scatter_plots)\n",
    "            scatter_labels = tuple(scatter_labels)\n",
    "\n",
    "        for l in lines:\n",
    "            li = plt.plot(l[\"x\"], l[\"y\"], color=s[\"color\"], linewidth=l[\"width\"], label=l[\"label\"])\n",
    "\n",
    "        if mse:\n",
    "            plt.suptitle(title)\n",
    "            plt.title(\"MSE: %.2f\" % mse, fontsize=10)\n",
    "        else:\n",
    "            plt.title(title)\n",
    "\n",
    "        if axis_labels:\n",
    "            plt.xlabel(axis_labels[\"x\"])\n",
    "            plt.ylabel(axis_labels[\"y\"])\n",
    "\n",
    "        if legend[\"type\"] == \"lines\":\n",
    "            plt.legend(loc=\"lower_left\")\n",
    "        elif legend[\"type\"] == \"scatter\" and scatter:\n",
    "            plt.legend(scatter_plots, scatter_labels, loc=legend[\"loc\"])\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the dataset X and the corresponding labels y in 2D using PCA.\n",
    "    def plot_in_2d(self, X, y=None, title=None, accuracy=None, legend_labels=None):\n",
    "        X_transformed = self._transform(X, dim=2)\n",
    "        x1 = X_transformed[:, 0]\n",
    "        x2 = X_transformed[:, 1]\n",
    "        class_distr = []\n",
    "\n",
    "        y = np.array(y).astype(int)\n",
    "\n",
    "        colors = [self.cmap(i) for i in np.linspace(0, 1, len(np.unique(y)))]\n",
    "\n",
    "        # Plot the different class distributions\n",
    "        for i, l in enumerate(np.unique(y)):\n",
    "            _x1 = x1[y == l]\n",
    "            _x2 = x2[y == l]\n",
    "            _y = y[y == l]\n",
    "            class_distr.append(plt.scatter(_x1, _x2, color=colors[i]))\n",
    "\n",
    "        # Plot legend\n",
    "        if not legend_labels is None: \n",
    "            plt.legend(class_distr, legend_labels, loc=1)\n",
    "\n",
    "        # Plot title\n",
    "        if title:\n",
    "            if accuracy:\n",
    "                perc = 100 * accuracy\n",
    "                plt.suptitle(title)\n",
    "                plt.title(\"Accuracy: %.1f%%\" % perc, fontsize=10)\n",
    "            else:\n",
    "                plt.title(title)\n",
    "\n",
    "        # Axis labels\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Plot the dataset X and the corresponding labels y in 3D using PCA.\n",
    "    def plot_in_3d(self, X, y=None):\n",
    "        X_transformed = self._transform(X, dim=3)\n",
    "        x1 = X_transformed[:, 0]\n",
    "        x2 = X_transformed[:, 1]\n",
    "        x3 = X_transformed[:, 2]\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(x1, x2, x3, c=y)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6405b044df7d297575459db63fc228bdb9d95a12369b8249bfbb6c77cae13e4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
